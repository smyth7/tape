{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tape import ProteinBertModel, TAPETokenizer\n",
    "model = ProteinBertModel.from_pretrained('bert-base')\n",
    "tokenizer = TAPETokenizer(vocab='iupac')  # iupac is the vocab for TAPE models, use unirep for the UniRep model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pfam Family: Hexapep, Clan: CL0536\n",
    "sequence = 'GCTVEDRCLIGMGAILLNGCVIGSGSLVAAGALITQ'\n",
    "token_ids = torch.tensor([tokenizer.encode(sequence)])\n",
    "output = model(token_ids)\n",
    "sequence_output = output[0]\n",
    "pooled_output = output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[ 2, 11,  7, 23, 25,  9,  8, 21,  7, 15, 13, 11, 16, 11,  5, 13, 15, 15,\n         17, 11,  7, 25, 13, 11, 22, 11, 22, 15, 25,  5,  5, 11,  5, 15, 13, 23,\n         20,  3]])"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pfam Family: Hexapep, Clan: CL0536\n",
    "sequence = 'GCTVEDRCLIGMGAILLNGCVIGSGSLVAAGALITQ'\n",
    "token_ids = torch.tensor([tokenizer.encode(sequence)])\n",
    "output = model(token_ids)\n",
    "sequence_output = output[0]\n",
    "pooled_output = output[1]\n",
    "\n",
    "# NOTE: pooled_output is *not* trained for the transformer, do not use\n",
    "# w/o fine-tuning. A better option for now is to simply take a mean of\n",
    "# the sequence outputimport torch\n",
    "from tape import ProteinBertModel, TAPETokenizer\n",
    "model = ProteinBertModel.from_pretrained('bert-base')\n",
    "tokenizer = TAPETokenizer(vocab='iupac')  # iupac is the vocab for TAPE models, use unirep for the UniRep model\n",
    "\n",
    "# Pfam Family: Hexapep, Clan: CL0536\n",
    "sequence = 'GCTVEDRCLIGMGAILLNGCVIGSGSLVAAGALITQ'\n",
    "token_ids = torch.tensor([tokenizer.encode(sequence)])\n",
    "output = model(token_ids)\n",
    "sequence_output = output[0]\n",
    "pooled_output = output[1]\n",
    "\n",
    "# NOTE: pooled_output is *not* trained for the transformer, do not use\n",
    "# w/o fine-tuning. A better option for now is to simply take a mean of\n",
    "# the sequence output"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bittapeconda899adf3d7264499bab1aac0192c5e209",
   "display_name": "Python 3.7.7 64-bit ('tape': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}